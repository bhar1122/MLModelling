{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Case Study - Whats Cooking (Kaggle Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libararies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import ensemble\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import nltk\n",
    "import random\n",
    "\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Datafiles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json('train.json')\n",
    "test = pd.read_json('test.json')\n",
    "submit = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploratory Data Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cuisine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35203</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17600</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  cuisine\n",
       "0  35203  italian\n",
       "1  17600  italian"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)\n",
    "test.head(2)\n",
    "submit.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing space within words from the ingredients column \n",
    "new = []\n",
    "for items in train.ingredients:\n",
    "    items = [item.replace(' ', '') for item in items]\n",
    "    new.append(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test = []\n",
    "for items in test.ingredients:\n",
    "    items = [item.replace(' ', '') for item in items]\n",
    "    new_test.append(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['romainelettuce', 'blackolives', 'grapetomatoes', 'garlic', 'pepper', 'purpleonion', 'seasoning', 'garbanzobeans', 'fetacheesecrumbles'], ['plainflour', 'groundpepper', 'salt', 'tomatoes', 'groundblackpepper', 'thyme', 'eggs', 'greentomatoes', 'yellowcornmeal', 'milk', 'vegetableoil'], ['eggs', 'pepper', 'salt', 'mayonaise', 'cookingoil', 'greenchilies', 'grilledchickenbreasts', 'garlicpowder', 'yellowonion', 'soysauce', 'butter', 'chickenlivers'], ['water', 'vegetableoil', 'wheat', 'salt'], ['blackpepper', 'shallots', 'cornflour', 'cayennepepper', 'onions', 'garlicpaste', 'milk', 'butter', 'salt', 'lemonjuice', 'water', 'chilipowder', 'passata', 'oil', 'groundcumin', 'bonelesschickenskinlessthigh', 'garammasala', 'doublecream', 'naturalyogurt', 'bayleaf'], ['plainflour', 'sugar', 'butter', 'eggs', 'freshgingerroot', 'salt', 'groundcinnamon', 'milk', 'vanillaextract', 'groundginger', 'powderedsugar', 'bakingpowder'], ['oliveoil', 'salt', 'mediumshrimp', 'pepper', 'garlic', 'choppedcilantro', 'jalapenochilies', 'flatleafparsley', 'skirtsteak', 'whitevinegar', 'seasalt', 'bayleaf', 'chorizosausage'], ['sugar', 'pistachionuts', 'whitealmondbark', 'flour', 'vanillaextract', 'oliveoil', 'almondextract', 'eggs', 'bakingpowder', 'driedcranberries'], ['oliveoil', 'purpleonion', 'freshpineapple', 'pork', 'poblanopeppers', 'corntortillas', 'cheddarcheese', 'groundblackpepper', 'salt', 'iceberglettuce', 'lime', 'jalapenochilies', 'choppedcilantrofresh'], ['choppedtomatoes', 'freshbasil', 'garlic', 'extra-virginoliveoil', 'koshersalt', 'flatleafparsley']]\n",
      "                                                   0\n",
      "0  [romainelettuce, blackolives, grapetomatoes, g...\n",
      "1  [plainflour, groundpepper, salt, tomatoes, gro...\n",
      "2  [eggs, pepper, salt, mayonaise, cookingoil, gr...\n",
      "3                 [water, vegetableoil, wheat, salt]\n",
      "4  [blackpepper, shallots, cornflour, cayennepepp...\n"
     ]
    }
   ],
   "source": [
    "# Removing List of Lists and creating additional column with new ingredient list \n",
    "print(new[0:10])\n",
    "new_transposed = zip(new)\n",
    "new = pd.DataFrame(new_transposed)\n",
    "print(new.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['bakingpowder', 'eggs', 'all-purposeflour', 'raisins', 'milk', 'whitesugar'], ['sugar', 'eggyolks', 'cornstarch', 'creamoftartar', 'bananas', 'vanillawafers', 'milk', 'vanillaextract', 'toastedpecans', 'eggwhites', 'lightrum'], ['sausagelinks', 'fennelbulb', 'fronds', 'oliveoil', 'cubanpeppers', 'onions'], ['meatcuts', 'filepowder', 'smokedsausage', 'okra', 'shrimp', 'andouillesausage', 'water', 'paprika', 'hotsauce', 'garliccloves', 'browning', 'lumpcrabmeat', 'vegetableoil', 'all-purposeflour', 'freshlygroundpepper', 'flatleafparsley', 'bonelesschickenskinlessthigh', 'driedthyme', 'whiterice', 'yellowonion', 'ham'], ['groundblackpepper', 'salt', 'sausagecasings', 'leeks', 'parmigianoreggianocheese', 'cornmeal', 'water', 'extra-virginoliveoil'], ['bakingpowder', 'all-purposeflour', 'peachslices', 'cornstarch', 'heavycream', 'lemonjuice', 'unsaltedbutter', 'salt', 'whitesugar'], ['grapejuice', 'orange', 'whitezinfandel'], ['groundginger', 'whitepepper', 'greenonions', 'orangejuice', 'sugar', 'Sriracha', 'vegetableoil', 'orangezest', 'chickenbroth', 'sesameseeds', 'bonelessskinlesschickenbreasts', 'cornstarch', 'whitevinegar', 'soysauce', 'largeeggs', 'garlic'], ['dicedonions', 'tacoseasoningmix', 'all-purposeflour', 'choppedcilantrofresh', 'groundcumin', 'groundcinnamon', 'vegetableoil', 'bittersweetchocolate', 'choppedgarlic', 'water', 'hotchilipowder', 'bonelessskinlesschickenbreasthalves', 'shreddedMontereyJackcheese', 'chickenbroth', 'Anaheimchile', 'creamcheese', 'driedoregano'], ['eggs', 'cherries', 'dates', 'darkmuscovadosugar', 'groundcinnamon', 'mixedspice', 'cake', 'vanillaextract', 'selfraisingflour', 'sultana', 'rum', 'raisins', 'prunes', 'glacecherries', 'butter', 'port']]\n",
      "                                                   0\n",
      "0  [bakingpowder, eggs, all-purposeflour, raisins...\n",
      "1  [sugar, eggyolks, cornstarch, creamoftartar, b...\n",
      "2  [sausagelinks, fennelbulb, fronds, oliveoil, c...\n",
      "3  [meatcuts, filepowder, smokedsausage, okra, sh...\n",
      "4  [groundblackpepper, salt, sausagecasings, leek...\n"
     ]
    }
   ],
   "source": [
    "print(new_test[0:10])\n",
    "new_test_transposed = zip(new_test)\n",
    "new_test = pd.DataFrame(new_test_transposed)\n",
    "print(new_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conacate additional column with train\n",
    "train = pd.concat([train,new],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.concat([test,new_test],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming new column \n",
    "train = train.rename(columns={0: \"ingredients_2\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.rename(columns={0: \"ingredients_2\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>ingredients_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10259</td>\n",
       "      <td>greek</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "      <td>[romainelettuce, blackolives, grapetomatoes, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25693</td>\n",
       "      <td>southern_us</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "      <td>[plainflour, groundpepper, salt, tomatoes, gro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id      cuisine                                        ingredients  \\\n",
       "0  10259        greek  [romaine lettuce, black olives, grape tomatoes...   \n",
       "1  25693  southern_us  [plain flour, ground pepper, salt, tomatoes, g...   \n",
       "\n",
       "                                       ingredients_2  \n",
       "0  [romainelettuce, blackolives, grapetomatoes, g...  \n",
       "1  [plainflour, groundpepper, salt, tomatoes, gro...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>ingredients_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18009</td>\n",
       "      <td>[baking powder, eggs, all-purpose flour, raisi...</td>\n",
       "      <td>[bakingpowder, eggs, all-purposeflour, raisins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28583</td>\n",
       "      <td>[sugar, egg yolks, corn starch, cream of tarta...</td>\n",
       "      <td>[sugar, eggyolks, cornstarch, creamoftartar, b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                        ingredients  \\\n",
       "0  18009  [baking powder, eggs, all-purpose flour, raisi...   \n",
       "1  28583  [sugar, egg yolks, corn starch, cream of tarta...   \n",
       "\n",
       "                                       ingredients_2  \n",
       "0  [bakingpowder, eggs, all-purposeflour, raisins...  \n",
       "1  [sugar, eggyolks, cornstarch, creamoftartar, b...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing commas (',' ) from ingredient2 and saving in data in additional column \n",
    "train['ingredients_1'] =train['ingredients_2'].apply(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['ingredients_1'] =test['ingredients_2'].apply(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>ingredients_2</th>\n",
       "      <th>ingredients_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10259</td>\n",
       "      <td>greek</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "      <td>[romainelettuce, blackolives, grapetomatoes, g...</td>\n",
       "      <td>romainelettuce blackolives grapetomatoes garli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25693</td>\n",
       "      <td>southern_us</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "      <td>[plainflour, groundpepper, salt, tomatoes, gro...</td>\n",
       "      <td>plainflour groundpepper salt tomatoes groundbl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20130</td>\n",
       "      <td>filipino</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cookingoil, gr...</td>\n",
       "      <td>eggs pepper salt mayonaise cookingoil greenchi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22213</td>\n",
       "      <td>indian</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "      <td>[water, vegetableoil, wheat, salt]</td>\n",
       "      <td>water vegetableoil wheat salt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13162</td>\n",
       "      <td>indian</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "      <td>[blackpepper, shallots, cornflour, cayennepepp...</td>\n",
       "      <td>blackpepper shallots cornflour cayennepepper o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id      cuisine                                        ingredients  \\\n",
       "0  10259        greek  [romaine lettuce, black olives, grape tomatoes...   \n",
       "1  25693  southern_us  [plain flour, ground pepper, salt, tomatoes, g...   \n",
       "2  20130     filipino  [eggs, pepper, salt, mayonaise, cooking oil, g...   \n",
       "3  22213       indian                [water, vegetable oil, wheat, salt]   \n",
       "4  13162       indian  [black pepper, shallots, cornflour, cayenne pe...   \n",
       "\n",
       "                                       ingredients_2  \\\n",
       "0  [romainelettuce, blackolives, grapetomatoes, g...   \n",
       "1  [plainflour, groundpepper, salt, tomatoes, gro...   \n",
       "2  [eggs, pepper, salt, mayonaise, cookingoil, gr...   \n",
       "3                 [water, vegetableoil, wheat, salt]   \n",
       "4  [blackpepper, shallots, cornflour, cayennepepp...   \n",
       "\n",
       "                                       ingredients_1  \n",
       "0  romainelettuce blackolives grapetomatoes garli...  \n",
       "1  plainflour groundpepper salt tomatoes groundbl...  \n",
       "2  eggs pepper salt mayonaise cookingoil greenchi...  \n",
       "3                      water vegetableoil wheat salt  \n",
       "4  blackpepper shallots cornflour cayennepepper o...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>ingredients_2</th>\n",
       "      <th>ingredients_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18009</td>\n",
       "      <td>[baking powder, eggs, all-purpose flour, raisi...</td>\n",
       "      <td>[bakingpowder, eggs, all-purposeflour, raisins...</td>\n",
       "      <td>bakingpowder eggs all-purposeflour raisins mil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28583</td>\n",
       "      <td>[sugar, egg yolks, corn starch, cream of tarta...</td>\n",
       "      <td>[sugar, eggyolks, cornstarch, creamoftartar, b...</td>\n",
       "      <td>sugar eggyolks cornstarch creamoftartar banana...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                        ingredients  \\\n",
       "0  18009  [baking powder, eggs, all-purpose flour, raisi...   \n",
       "1  28583  [sugar, egg yolks, corn starch, cream of tarta...   \n",
       "\n",
       "                                       ingredients_2  \\\n",
       "0  [bakingpowder, eggs, all-purposeflour, raisins...   \n",
       "1  [sugar, eggyolks, cornstarch, creamoftartar, b...   \n",
       "\n",
       "                                       ingredients_1  \n",
       "0  bakingpowder eggs all-purposeflour raisins mil...  \n",
       "1  sugar eggyolks cornstarch creamoftartar banana...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split \n",
    "train_corpus = train['ingredients_1']\n",
    "test_corpus = test['ingredients_1']\n",
    "y = train['cuisine']\n",
    "X  = train_corpus\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39774,)\n",
      "(9944,)\n",
      "(27841,)\n",
      "(11933,)\n"
     ]
    }
   ],
   "source": [
    "print(train_corpus.shape)\n",
    "print(test_corpus.shape)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove array\n",
    "#train['ingredients_clean_string'] = [' , '.join(z).strip() for z in train['ingredients']]   \n",
    "#test['ingredients_clean_string'] = [' , '.join(z).strip() for z in test['ingredients']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating TFIDF vector metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectorizer = TfidfVectorizer(stop_words='english',\n",
    "                             ngram_range = ( 1 , 1 ),analyzer=\"word\", \n",
    "                             max_df = .57 , binary=False , token_pattern=r'\\w+' , sublinear_tf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfidf=train_vectorizer.fit_transform(X_train).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27841, 6171)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_tfidf = train_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11933, 6171)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tfidf=train_vectorizer.transform(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9944, 6171)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11933x6171 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 130090 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9944x6171 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 108646 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model - 1 SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=LinearSVC(C=0.8, class_weight=None, dual=False,\n",
       "                                 fit_intercept=True, intercept_scaling=1,\n",
       "                                 loss='squared_hinge', max_iter=1000,\n",
       "                                 multi_class='ovr', penalty='l2',\n",
       "                                 random_state=None, tol=0.0001, verbose=0),\n",
       "             iid='deprecated', n_jobs=None, param_grid={'C': [1, 10]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model = LinearSVC(C=0.80, penalty=\"l2\", dual=False)\n",
    "parameters = {'C':[1, 10]}\n",
    "classifier = GridSearchCV(model, parameters)\n",
    "classifier.fit(train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = classifier.predict(train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = classifier.predict(val_tfidf)\n",
    "#test_predict = classifier.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = classifier.predict(test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.95      0.86      0.90       333\n",
      "     british       0.87      0.76      0.81       582\n",
      "cajun_creole       0.90      0.87      0.88      1114\n",
      "     chinese       0.90      0.95      0.93      1870\n",
      "    filipino       0.94      0.88      0.91       534\n",
      "      french       0.83      0.82      0.82      1857\n",
      "       greek       0.93      0.86      0.90       819\n",
      "      indian       0.93      0.97      0.95      2094\n",
      "       irish       0.92      0.80      0.86       483\n",
      "     italian       0.90      0.96      0.93      5432\n",
      "    jamaican       0.95      0.91      0.93       375\n",
      "    japanese       0.95      0.85      0.90       994\n",
      "      korean       0.96      0.93      0.95       576\n",
      "     mexican       0.96      0.97      0.96      4482\n",
      "    moroccan       0.95      0.93      0.94       561\n",
      "     russian       0.90      0.79      0.84       345\n",
      " southern_us       0.86      0.92      0.89      3065\n",
      "     spanish       0.88      0.70      0.78       688\n",
      "        thai       0.94      0.92      0.93      1045\n",
      "  vietnamese       0.94      0.83      0.88       592\n",
      "\n",
      "    accuracy                           0.91     27841\n",
      "   macro avg       0.92      0.87      0.89     27841\n",
      "weighted avg       0.91      0.91      0.91     27841\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.74      0.58      0.65       134\n",
      "     british       0.52      0.44      0.48       222\n",
      "cajun_creole       0.76      0.72      0.74       432\n",
      "     chinese       0.78      0.85      0.82       803\n",
      "    filipino       0.71      0.59      0.64       221\n",
      "      french       0.62      0.61      0.61       789\n",
      "       greek       0.76      0.71      0.74       356\n",
      "      indian       0.84      0.89      0.87       909\n",
      "       irish       0.59      0.46      0.52       184\n",
      "     italian       0.81      0.88      0.84      2406\n",
      "    jamaican       0.84      0.74      0.78       151\n",
      "    japanese       0.82      0.69      0.75       429\n",
      "      korean       0.82      0.76      0.79       254\n",
      "     mexican       0.90      0.92      0.91      1956\n",
      "    moroccan       0.80      0.74      0.77       260\n",
      "     russian       0.63      0.41      0.50       144\n",
      " southern_us       0.72      0.81      0.76      1255\n",
      "     spanish       0.63      0.47      0.54       301\n",
      "        thai       0.81      0.76      0.78       494\n",
      "  vietnamese       0.66      0.54      0.59       233\n",
      "\n",
      "    accuracy                           0.78     11933\n",
      "   macro avg       0.74      0.68      0.70     11933\n",
      "weighted avg       0.78      0.78      0.78     11933\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train, train_pred))\n",
    "print(classification_report(y_test, val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict = pd.DataFrame(test_pred)\n",
    "sub = pd.concat([test['id'],test_predict],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18009</td>\n",
       "      <td>british</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28583</td>\n",
       "      <td>southern_us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41580</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29752</td>\n",
       "      <td>cajun_creole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35687</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id             0\n",
       "0  18009       british\n",
       "1  28583   southern_us\n",
       "2  41580       italian\n",
       "3  29752  cajun_creole\n",
       "4  35687       italian"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"svc.csv\",index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cuisine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35203</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17600</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35200</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17602</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17605</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  cuisine\n",
       "0  35203  italian\n",
       "1  17600  italian\n",
       "2  35200  italian\n",
       "3  17602  italian\n",
       "4  17605  italian"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       18009\n",
       "1       28583\n",
       "2       41580\n",
       "3       29752\n",
       "4       35687\n",
       "        ...  \n",
       "9939    30246\n",
       "9940    36028\n",
       "9941    22339\n",
       "9942    42525\n",
       "9943     1443\n",
       "Name: id, Length: 9944, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = pd.DataFrame(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.concat([test['id'],test_pred],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18009</td>\n",
       "      <td>british</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28583</td>\n",
       "      <td>southern_us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41580</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29752</td>\n",
       "      <td>cajun_creole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35687</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id             0\n",
       "0  18009       british\n",
       "1  28583   southern_us\n",
       "2  41580       italian\n",
       "3  29752  cajun_creole\n",
       "4  35687       italian"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('svm.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Model 2: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(train_tfidf, y_train)\n",
    "train_pred_rf = rf.predict(train_tfidf)\n",
    "val_pred_rf = rf.predict(val_tfidf)\n",
    "test_pred_rf = rf.predict(test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       1.00      1.00      1.00       320\n",
      "     british       1.00      1.00      1.00       583\n",
      "cajun_creole       1.00      1.00      1.00      1059\n",
      "     chinese       1.00      1.00      1.00      1846\n",
      "    filipino       1.00      1.00      1.00       525\n",
      "      french       1.00      1.00      1.00      1897\n",
      "       greek       1.00      1.00      1.00       828\n",
      "      indian       1.00      1.00      1.00      2096\n",
      "       irish       1.00      1.00      1.00       476\n",
      "     italian       1.00      1.00      1.00      5479\n",
      "    jamaican       1.00      1.00      1.00       357\n",
      "    japanese       1.00      1.00      1.00       968\n",
      "      korean       1.00      1.00      1.00       574\n",
      "     mexican       1.00      1.00      1.00      4543\n",
      "    moroccan       1.00      1.00      1.00       578\n",
      "     russian       1.00      1.00      1.00       337\n",
      " southern_us       1.00      1.00      1.00      3059\n",
      "     spanish       1.00      1.00      1.00       678\n",
      "        thai       1.00      1.00      1.00      1076\n",
      "  vietnamese       1.00      1.00      1.00       562\n",
      "\n",
      "    accuracy                           1.00     27841\n",
      "   macro avg       1.00      1.00      1.00     27841\n",
      "weighted avg       1.00      1.00      1.00     27841\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.89      0.39      0.54       147\n",
      "     british       0.51      0.15      0.24       221\n",
      "cajun_creole       0.79      0.58      0.67       487\n",
      "     chinese       0.67      0.87      0.76       827\n",
      "    filipino       0.79      0.43      0.56       230\n",
      "      french       0.54      0.47      0.50       749\n",
      "       greek       0.79      0.42      0.55       347\n",
      "      indian       0.79      0.88      0.83       907\n",
      "       irish       0.65      0.20      0.31       191\n",
      "     italian       0.67      0.90      0.77      2359\n",
      "    jamaican       0.88      0.30      0.45       169\n",
      "    japanese       0.83      0.56      0.67       455\n",
      "      korean       0.87      0.55      0.68       256\n",
      "     mexican       0.79      0.91      0.84      1895\n",
      "    moroccan       0.84      0.45      0.59       243\n",
      "     russian       0.87      0.22      0.36       152\n",
      " southern_us       0.55      0.74      0.63      1261\n",
      "     spanish       0.73      0.20      0.31       311\n",
      "        thai       0.73      0.67      0.70       463\n",
      "  vietnamese       0.84      0.37      0.51       263\n",
      "\n",
      "    accuracy                           0.70     11933\n",
      "   macro avg       0.75      0.51      0.57     11933\n",
      "weighted avg       0.72      0.70      0.68     11933\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, train_pred_rf))\n",
    "print(classification_report(y_test, val_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.metrics import classification_report\n",
    "\n",
    "#rfc = RandomForestClassifier(n_jobs=-1, max_features='sqrt') \n",
    " \n",
    "# Use a grid over parameters of interest\n",
    "#param_grid = { \n",
    "           \"n_estimators\" : [300, 500, 700],\n",
    "           \"max_depth\" : [None, 1, 2, 3],\n",
    "           \"min_samples_leaf\" : [1, 2, 3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = GridSearchCV(estimator=rfc, param_grid=param_grid,cv=5)\n",
    "#clf.fit(train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rfc_best = RandomForestClassifier(**clf.best_params_)\n",
    "#rfc_best.fit(train_tfidf, y_train)\n",
    "#train_pred_rfc_best = rfc_best.predict(train_tfidf)\n",
    "#val_pred_rfc_best = rfc_best.predict(val_tfidf)\n",
    "#test_pred_rfc_best = rfc_best.predict(test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       1.00      1.00      1.00       320\n",
      "     british       1.00      1.00      1.00       583\n",
      "cajun_creole       1.00      1.00      1.00      1059\n",
      "     chinese       1.00      1.00      1.00      1846\n",
      "    filipino       1.00      1.00      1.00       525\n",
      "      french       1.00      1.00      1.00      1897\n",
      "       greek       1.00      1.00      1.00       828\n",
      "      indian       1.00      1.00      1.00      2096\n",
      "       irish       1.00      1.00      1.00       476\n",
      "     italian       1.00      1.00      1.00      5479\n",
      "    jamaican       1.00      1.00      1.00       357\n",
      "    japanese       1.00      1.00      1.00       968\n",
      "      korean       1.00      1.00      1.00       574\n",
      "     mexican       1.00      1.00      1.00      4543\n",
      "    moroccan       1.00      1.00      1.00       578\n",
      "     russian       1.00      1.00      1.00       337\n",
      " southern_us       1.00      1.00      1.00      3059\n",
      "     spanish       1.00      1.00      1.00       678\n",
      "        thai       1.00      1.00      1.00      1076\n",
      "  vietnamese       1.00      1.00      1.00       562\n",
      "\n",
      "    accuracy                           1.00     27841\n",
      "   macro avg       1.00      1.00      1.00     27841\n",
      "weighted avg       1.00      1.00      1.00     27841\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.89      0.39      0.54       147\n",
      "     british       0.51      0.15      0.24       221\n",
      "cajun_creole       0.79      0.58      0.67       487\n",
      "     chinese       0.67      0.87      0.76       827\n",
      "    filipino       0.79      0.43      0.56       230\n",
      "      french       0.54      0.47      0.50       749\n",
      "       greek       0.79      0.42      0.55       347\n",
      "      indian       0.79      0.88      0.83       907\n",
      "       irish       0.65      0.20      0.31       191\n",
      "     italian       0.67      0.90      0.77      2359\n",
      "    jamaican       0.88      0.30      0.45       169\n",
      "    japanese       0.83      0.56      0.67       455\n",
      "      korean       0.87      0.55      0.68       256\n",
      "     mexican       0.79      0.91      0.84      1895\n",
      "    moroccan       0.84      0.45      0.59       243\n",
      "     russian       0.87      0.22      0.36       152\n",
      " southern_us       0.55      0.74      0.63      1261\n",
      "     spanish       0.73      0.20      0.31       311\n",
      "        thai       0.73      0.67      0.70       463\n",
      "  vietnamese       0.84      0.37      0.51       263\n",
      "\n",
      "    accuracy                           0.70     11933\n",
      "   macro avg       0.75      0.51      0.57     11933\n",
      "weighted avg       0.72      0.70      0.68     11933\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, train_pred_rf))\n",
    "print(classification_report(y_test, val_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict_rf = pd.DataFrame(test_pred_rf)\n",
    "sub = pd.concat([test['id'],test_predict_rf],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"rf.csv\",index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Model 3: Stochastic Gradient Descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = SGDClassifier(shuffle=True, random_state=101)\n",
    "sgd.fit(train_tfidf,y_train)\n",
    "train_pred_sgd = sgd.predict(train_tfidf)\n",
    "val_pred_sgd = sgd.predict(val_tfidf)\n",
    "test_pred_sgd = sgd.predict(test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.88      0.53      0.66       320\n",
      "     british       0.90      0.44      0.59       583\n",
      "cajun_creole       0.86      0.76      0.81      1059\n",
      "     chinese       0.84      0.90      0.87      1846\n",
      "    filipino       0.89      0.71      0.79       525\n",
      "      french       0.77      0.64      0.70      1897\n",
      "       greek       0.84      0.76      0.80       828\n",
      "      indian       0.87      0.94      0.90      2096\n",
      "       irish       0.86      0.50      0.63       476\n",
      "     italian       0.77      0.95      0.85      5479\n",
      "    jamaican       0.85      0.76      0.80       357\n",
      "    japanese       0.93      0.72      0.81       968\n",
      "      korean       0.92      0.80      0.86       574\n",
      "     mexican       0.91      0.94      0.92      4543\n",
      "    moroccan       0.91      0.76      0.83       578\n",
      "     russian       0.87      0.52      0.65       337\n",
      " southern_us       0.74      0.87      0.80      3059\n",
      "     spanish       0.88      0.41      0.56       678\n",
      "        thai       0.78      0.86      0.82      1076\n",
      "  vietnamese       0.90      0.48      0.62       562\n",
      "\n",
      "    accuracy                           0.83     27841\n",
      "   macro avg       0.86      0.71      0.76     27841\n",
      "weighted avg       0.83      0.83      0.82     27841\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.80      0.46      0.58       147\n",
      "     british       0.61      0.24      0.34       221\n",
      "cajun_creole       0.78      0.68      0.72       487\n",
      "     chinese       0.79      0.86      0.82       827\n",
      "    filipino       0.69      0.55      0.61       230\n",
      "      french       0.64      0.56      0.59       749\n",
      "       greek       0.74      0.64      0.68       347\n",
      "      indian       0.83      0.90      0.87       907\n",
      "       irish       0.72      0.37      0.49       191\n",
      "     italian       0.75      0.91      0.82      2359\n",
      "    jamaican       0.77      0.65      0.71       169\n",
      "    japanese       0.90      0.67      0.77       455\n",
      "      korean       0.84      0.71      0.77       256\n",
      "     mexican       0.88      0.93      0.90      1895\n",
      "    moroccan       0.86      0.71      0.78       243\n",
      "     russian       0.76      0.40      0.53       152\n",
      " southern_us       0.63      0.80      0.71      1261\n",
      "     spanish       0.76      0.35      0.48       311\n",
      "        thai       0.71      0.77      0.74       463\n",
      "  vietnamese       0.82      0.37      0.51       263\n",
      "\n",
      "    accuracy                           0.76     11933\n",
      "   macro avg       0.76      0.63      0.67     11933\n",
      "weighted avg       0.77      0.76      0.75     11933\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, train_pred_sgd))\n",
    "print(classification_report(y_test, val_pred_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict_sgd = pd.DataFrame(test_pred_sgd)\n",
    "sub = pd.concat([test['id'],test_predict_sgd],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"sgd.csv\",index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle Dataset: Whats Cooking\n",
    "\n",
    "Some of our strongest geographic and cultural associations are tied to a \n",
    "region's local foods. This playground competitions asks you to predict \n",
    "the category of a dish's cuisine given a list of its ingredients. \n",
    "Submissions are evaluated on the categorization accuracy \n",
    "(the percent of dishes that you correctly classify).Submission should \n",
    "predict the cuisine for each recipe in the test set. \n",
    "\n",
    "Data description: \n",
    "In the dataset, recipe id, the type of cuisine, and the list of ingredients \n",
    "of each recipe (of variable length) is included. The data is stored in \n",
    "JSON format. In the test file test.json, the format of a recipe is the same as train.json, only the cuisine type is removed, as\n",
    "it is the target variable to be predicted.\n",
    "\n",
    "Data Fields: \n",
    "\n",
    "train.json - the training set containing recipes id, type of cuisine, and list of ingredients\n",
    "test.json - the test set containing recipes id, and list of ingredients\n",
    "sample_submission.csv - a sample submission file in the correct format\n",
    "\n",
    "Steps in Data Processing Conducted:\n",
    "1. Removing space within words from the ingredients column \n",
    "2. Removing the list of lists within the 'ingredients' column\n",
    "3. Creating an addditional column to remove the list of lists, hypen \n",
    "and then concatinating to orginal dataframe - now the new column \n",
    "is a cleaned column for applying TFIDF vectorisation \n",
    "4.  Data was split into 80:20 for training and validation \n",
    "\n",
    "\n",
    "Models Applied: \n",
    "Support Vector Machine, \n",
    "Random Forest, \n",
    "Stochastic Gradient Descent\n",
    "\n",
    "Error Metrics for evaluation - Accuracy, recall, precision, F1 score.\n",
    "\n",
    "\n",
    "Model Results: \n",
    "\n",
    "Support Vector Classifier performed better compared to Support Vector \n",
    "Machine, giving the overall ranking closer to 822 on the ranking on the \n",
    "Pvt Leaderscoreboard\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
